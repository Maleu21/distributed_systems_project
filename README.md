# ğŸ“š Projet MapReduce DistribuÃ© â€“ WordCount & Tri dâ€™Occurrences

## ğŸ§  Contexte

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du module **SystÃ¨mes RÃ©partis (BGD701)** du MastÃ¨re Expert Data IA et MLops de TÃ©lÃ©com Paris. Il vise Ã  implÃ©menter un systÃ¨me distribuÃ© basÃ© sur le paradigme **MapReduce** pour effectuer un **wordcount** sur des fichiers texte rÃ©partis sur plusieurs machines, puis trier les mots selon leurs occurrences.

Ce projet pÃ©dagogique permet d'explorer les problÃ©matiques de parallÃ©lisation, de rÃ©partition de charge, de robustesse des systÃ¨mes distribuÃ©s et dâ€™Ã©valuer les performances via la **loi dâ€™Amdahl**.

---

## ğŸ“Œ Objectifs

- ImplÃ©menter un systÃ¨me MapReduce complet :
  - **Wordcount** distribuÃ©
  - **Tri des mots** par frÃ©quence
- Automatiser le dÃ©ploiement sur plusieurs machines virtuelles via SSH
- Analyser la **scalabilitÃ©** et les **limitations** des systÃ¨mes rÃ©partis

---

## âš™ï¸ Architecture

Le projet sâ€™organise en **deux MapReduce successifs**, dÃ©ployÃ©s via un script `deploy.sh`.

### ğŸ—‚ 1. Premier MapReduce : WordCount
#### Script : `script.py`

- **Mapping** : Extraction des mots et initialisation des occurrences (`<mot> 1`)
- **Shuffle** : RÃ©partition des mots selon leur hachage MD5
- **Reduce** : AgrÃ©gation des occurrences par mot
- **AgrÃ©gation finale** : Centralisation des rÃ©sultats dans un fichier global

---

### ğŸ—‚ 2. Second MapReduce : Tri par Occurrence
#### Script : `script_f.py`

- **Mapping** : Inversion `(mot, occ)` â†’ `(occ, mot)` pour tri
- **Shuffle** : RÃ©partition Ã©quilibrÃ©e via hachage SHA-256
- **Reduce** : Tri local par frÃ©quence dÃ©croissante et ordre alphabÃ©tique
- **AgrÃ©gation finale** : Fusion des rÃ©sultats triÃ©s en un fichier final

---

### ğŸ§ª Script de DÃ©ploiement : `deploy.sh`

- **Initialisation** : Configuration SSH, nettoyage de lâ€™environnement
- **PrÃ©paration** :
  - DÃ©tection des machines disponibles
  - TÃ©lÃ©chargement et dÃ©coupage des fichiers sources
- **Distribution** : RÃ©partition Ã©quitable des donnÃ©es sur les machines
- **ExÃ©cution** :
  - DÃ©ploiement et exÃ©cution du `script.py` pour le WordCount
  - Puis du `script_f.py` pour le tri

---

## ğŸ“Š Performance & Loi dâ€™Amdahl

Lâ€™accÃ©lÃ©ration thÃ©orique est calculÃ©e selon la **loi dâ€™Amdahl** :

```
S(N) = 1 / ((1 - P) + (P / N))
```

- **Observation** : Le gain de performance diminue avec le nombre de machines Ã  cause :
  - du faible pourcentage parallÃ©lisable
  - du coÃ»t des communications inter-machines
- **Exemples** :
  - 10 machines â†’ Speedup â‰ˆ 1.17
  - 30 machines â†’ Speedup â‰ˆ 1.08

---

## ğŸ“ Structure du projet

```
â”œâ”€â”€ deploy.sh           # Script de dÃ©ploiement automatisÃ©
â”œâ”€â”€ script.py           # Script MapReduce - WordCount
â”œâ”€â”€ script_f.py         # Script MapReduce - Tri des mots
â”œâ”€â”€ machines.txt        # Liste des machines virtuelles (IP / hostnames)
â”œâ”€â”€ log.txt             # Fichier de logs (temps, erreurs, phases)
â””â”€â”€ rÃ©sultats/          # RÃ©pertoire pour les fichiers finaux gÃ©nÃ©rÃ©s
```

---

## ğŸš€ Lancer le projet

1. **Configurer** `machines.txt` avec vos machines SSH accessibles
2. **Placer** les fichiers sources Ã  traiter dans le rÃ©pertoire dÃ©fini dans `deploy.sh`
3. **ExÃ©cuter** le script de dÃ©ploiement :

```bash
bash deploy.sh
```

4. Les rÃ©sultats finaux sont disponibles dans le dossier `rÃ©sultats/`

---

## âœï¸ Auteur

- **MaÃ«l PACAUD**
- Promotion **MSBGD**
- Module **BGD701 â€“ SystÃ¨mes RÃ©partis**

---

## ğŸ“œ Licence

Projet acadÃ©mique â€“ Utilisation pÃ©dagogique uniquement.
